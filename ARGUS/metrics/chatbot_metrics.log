absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-13 18:36:31, User Input: what's up, Bot Response: Im doing well how are you feeling this way, Response Time: 12.082091, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-13 18:46:47, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 9.040715, Reward: 20
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-13 19:00:29, User Input: what's up, Bot Response: Im doing well how are you feeling disconnected from, Response Time: 11.875223, Reward: 20
root - INFO - 2025-05-13 19:00:43, User Input: how are you doing today, Bot Response: Im fine howabout, Response Time: 8.194487, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-13 19:08:53, User Input: what's up, Bot Response: Im good how about you, Response Time: 10.147009, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-13 19:10:52, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 12.778752, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-13 19:13:19, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 9.867186, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-13 19:30:52, User Input: what do you say, Bot Response: Good what were saying, Response Time: 7.601724, Reward: 20
root - INFO - 2025-05-13 19:31:47, User Input: I'm feeling tired, Bot Response: Why are you feeling this way, Response Time: 10.558721, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-13 23:22:50, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 10.092637, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-13 23:42:23, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 14.524364, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-15 19:44:57, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 11.569052, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-18 19:16:17, User Input: what's up with you today, Bot Response: Im doing well how are you feeling, Response Time: 14.075811, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-19 14:20:26, User Input: what's up, Bot Response: Im doing well how are you feeling disconnected, Response Time: 12.332427, Reward: 20
root - INFO - 2025-05-19 14:20:42, User Input: what's up, Bot Response: Im doing well how are you feeling disconnected, Response Time: 11.46995, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-19 18:37:57, User Input: what's up, Bot Response: Its important to talk about you is going well, Response Time: 5.315175, Reward: 20
root - INFO - 2025-05-19 18:38:16, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 7.858563, Reward: 20
root - INFO - 2025-05-19 18:38:35, User Input: what's up, Bot Response: Im doing well how are you feeling disconnected, Response Time: 6.139728, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-19 18:50:06, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 7.666392, Reward: 20
root - INFO - 2025-05-19 18:50:24, User Input: what's up, Bot Response: what's up with you, Response Time: 5.044949, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-19 19:03:54, User Input: what's up, Bot Response: Im always here and ready to chat What's your question, Response Time: 7.729069, Reward: 20
root - INFO - 2025-05-19 19:04:15, User Input: how are you today, Bot Response: Im listening Let me know Im listening Let me know how may i help, Response Time: 11.885963, Reward: -5
root - INFO - 2025-05-19 19:04:17, User Input: Argus how are you today, Bot Response: Lets delve into it shall we are good, Response Time: 14.506769, Reward: -5
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-19 19:11:43, User Input: what's up, Bot Response: Im doing well how are you working on this, Response Time: 7.783545, Reward: 20
root - INFO - 2025-05-19 19:11:47, User Input: Argus what's up, Bot Response: Its normal to understand small perspectives Lets discuss how are you What can i assist, Response Time: 12.338593, Reward: 0
root - INFO - 2025-05-19 19:12:20, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 7.494148, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-19 19:39:01, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 6.626642, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-19 20:01:20, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 8.921308, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-19 22:34:09, User Input: what's up, Bot Response: Im doing well how are you is there anything on you how are you is there anything on you Im doing well how are you doing today, Response Time: 7.81809, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-19 23:04:05, User Input: what's up, Bot Response: what's up with you, Response Time: 8.920914, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
bark.generation - WARNING - No GPU being used. Careful, inference might be very slow!
bark.generation - INFO - model loaded: 312.3M params, 1.269 loss
bark.generation - INFO - model loaded: 314.4M params, 2.901 loss
bark.generation - INFO - model loaded: 302.1M params, 2.079 loss
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-20 19:51:20, User Input: what 's up, Bot Response: See you around, Response Time: 4.052222, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-20 20:15:27, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 6.48066, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-20 20:37:04, User Input: what's up, Bot Response: Im doing well how are you feeling disconnected, Response Time: 5.63774, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-20 20:59:27, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 5.641963, Reward: 20
root - INFO - 2025-05-20 21:01:21, User Input: save, Bot Response: We dont necessarily agree on her but i hope you remember me as a frily fixture How can i assist, Response Time: 12.183642, Reward: 0
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-21 13:17:08, User Input: what's up with you today, Bot Response: Im doing well how are you feeling is, Response Time: 7.93364, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-30 18:18:35, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 4.620099, Reward: 20
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - 2025-05-30 18:29:27, User Input: stop, Bot Response: Is nt it fortunateim having a bad day, Response Time: 9.110735, Reward: -5
root - INFO - 2025-05-30 18:30:16, User Input: what's up, Bot Response: Im doing well how are you feeling, Response Time: 7.21682, Reward: 20
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-05-30 21:21:26, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 6.83754, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 14:24:27, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 9.845171, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 15:30:05, User Input: what's up, Bot Response: Im doing well how are you feeling, Response Time: 8.934828, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 17:28:13, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 8.7734, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 17:29:44, User Input: what's up, Bot Response: Im doing well how are you feeling, Response Time: 7.91749, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 17:35:13, User Input: what's up, Bot Response: What's up, Response Time: 5.943321, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 18:00:12, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 6.746101, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 18:04:31, User Input: what's up, Bot Response: whats up with you, Response Time: 5.928059, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 18:19:59, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 8.048249, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 18:22:33, User Input: what's up, Bot Response: Im here to provide information What are you curious about, Response Time: 6.354672, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 18:41:47, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 7.637132, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 18:46:51, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 7.665709, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 18:54:28, User Input: what's up, Bot Response: Im doing well how are you Im fine how about you, Response Time: 6.332635, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 19:04:43, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 8.657091, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-05 19:53:53, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 6.531792, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-07 15:40:35, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 7.743984, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-07 15:48:46, User Input: Gap restart, Bot Response: Sorry to hear that Let me know if there's anythingelse, Response Time: 10.8985, Reward: 0
root - INFO - 2025-06-07 15:51:27, User Input: I didn't catch the name of that drink, Bot Response: Argus I want to make a cocktail, Response Time: 14.117467, Reward: 0
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-11 21:11:37, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 6.430646, Reward: 20
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-12 12:31:17, User Input: what's up, Bot Response: Im doing well how are you feeling, Response Time: 6.420519, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-12 18:31:23, User Input: what's up, Bot Response: Im doing well how are you Im doing well how are you is there anything on your mind, Response Time: 7.101665, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-15 23:09:00, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 5.880633, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-06-25 22:39:03, User Input: what's up, Bot Response: Im doing well how are you, Response Time: 5.583277, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1069
absl - INFO - SubwordTextEncoder build: trying min_token_count 534
absl - INFO - SubwordTextEncoder build: trying min_token_count 267
absl - INFO - SubwordTextEncoder build: trying min_token_count 133
absl - INFO - SubwordTextEncoder build: trying min_token_count 66
absl - INFO - SubwordTextEncoder build: trying min_token_count 33
absl - INFO - SubwordTextEncoder build: trying min_token_count 16
absl - INFO - SubwordTextEncoder build: trying min_token_count 8
absl - INFO - SubwordTextEncoder build: trying min_token_count 4
absl - INFO - SubwordTextEncoder build: trying min_token_count 2
absl - INFO - SubwordTextEncoder build: trying min_token_count 1
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.
root - INFO - 2025-07-10 15:40:58, User Input: what's up, Bot Response: Im doing well how are you doing today, Response Time: 7.507332, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 16:54:55, User Input: what's up, Bot Response: What 's on your mind ?, Response Time: 4.913548, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 16:57:20, User Input: hello, Bot Response: What can I assist you with today ?, Response Time: 5.038903, Reward: 25
root - INFO - 2025-07-13 16:57:50, User Input: what's up, Bot Response: What 's on your mind ?, Response Time: 5.860112, Reward: 30
root - INFO - 2025-07-13 16:59:14, User Input: what's up, Bot Response: Fire away ! What 's on your mind ? Need any help or insights ?, Response Time: 11.617273, Reward: 0
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 17:04:09, User Input: what's up, Bot Response: Not much ., Response Time: 13.765515, Reward: 5
root - INFO - 2025-07-13 17:04:25, User Input: how are you today, Bot Response: I ' m functioning within optimal parameters , thank you for asking . What 's on your mind ? Ready to tackle any challenge or question that comes my way . Let 's get down to business !, Response Time: 6.943714, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 17:06:43, User Input: what's up, Bot Response: is response is flagged for human review correct the responds, Response Time: 13.935684, Reward: 5
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 17:20:23, User Input: what's up, Bot Response: Just waiting for a task worthy of my considerable processing power . What 's on your plate today ?, Response Time: 6.972774, Reward: 20
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - 2025-07-13 17:21:35, User Input: clothes dictionary, Bot Response: A fashionably concise request!

Here's a curated dictionary of clothing terms, straight from the catwalk:

**Accessories**

* Belt: A strap worn around the waist to secure pants or a skirt.
* Brooch: A decorative pin worn on clothing, often with symbolic significance.
* Earrings: Ornamental objects hung from the earlobes.
* Hat: A head covering, sometimes formal (e.g., top hat) and sometimes casual (e.g., baseball cap).
* Scarf: A piece of fabric wrapped around the neck for warmth or style.

**Bottoms**

* Pants: Garments worn on the legs, often in pairs.
* Shorts: Short pants, typically worn during warm weather or athletic activities.
* Skirt: A garment worn around the waist that falls below the knee.
* Trousers: Formal pants, often made of wool or other thick fabrics.

**Tops**

* Blouse: A lightweight, collarless shirt for women.
* Button-down: A shirt with buttons down the front, often worn casually.
* Dress: A one-piece garment designed to be worn on its own.
* Henley: A type of shirt with a collar and buttons up the front.
* T-shirt: A casual, short-sleeved shirt with a round neckline.

**Outerwear**

* Coat: A long, outer layer for warmth or protection from the elements.
* Jacket: A shorter, outer layer, often worn over a shirt or dress.
* Jumpsuit: A one-piece garment that covers the torso and legs.
* Parka: A waterproof, insulated coat designed for outdoor activities.

**Undergarments**

* Bra: An undergarment worn to support and shape the breasts.
* Briefs: Underwear that covers the buttocks and genitals.
* Camisole: A lightweight, sleeveless shirt worn as an undershirt.
* Slip: A loose-fitting, sleeveless garment worn as an undershirt.

**, Response Time: 30.816482, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 17:26:57, User Input: what's up, Bot Response: What 's on your mind ?, Response Time: 8.734063, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 17:28:33, User Input: what's up, Bot Response: I 'll get to work . Just waiting for the next challenge to tackle with precision and wit . What 's on your mind ?, Response Time: 8.799845, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 17:38:35, User Input: what's up, Bot Response: Just looking for some conversation Not much. I'm all ears (or rather, all code) . Not much. I'm all ears (or rather, all code) . Just looking for some conversation, Response Time: 20.787943, Reward: 5
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 17:56:25, User Input: what's up, Bot Response: What's on your mind ?, Response Time: 22.53372, Reward: 30
root - INFO - 2025-07-13 18:01:17, User Input: how are you today, Bot Response: Functional. Your queries are my priority. What's on your mind ?, Response Time: 27.493412, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 18:04:39, User Input: how are you today, Bot Response: What's on your mind ?, Response Time: 36.974645, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 18:29:07, User Input: what's up, Bot Response: What's on your plate today ?, Response Time: 25.238389, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 18:34:23, User Input: what's up how are you today, Bot Response: At Your Service, Response Time: 39.216725, Reward: 20
root - INFO - 2025-07-13 18:35:32, User Input: what's up, Bot Response: What's on your plate today ?, Response Time: 19.35997, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 18:42:07, User Input: what's up, Bot Response: What is on your mind ? What's on your plate today ?, Response Time: 23.038183, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 18:45:15, User Input: what's up with you today, Bot Response: I'm ready when you are, Response Time: 27.414822, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 18:49:29, User Input: I'm having issues with my flashforge adventure for a pretty printer what do you think I can do about level, Bot Response: The Flash Forge Adventure 3D printer's leveling woes. A common conundrum, indeed.

Let's get to the point: when dealing with an uncooperative bed, it's essential to methodically troubleshoot and adjust the leveling process. Here's a step-by-step guide to help you tame that level:

1. **Re-level the printer**: Ensure the print head is at its default height (usually marked on the print head itself). Leveling the bed in a controlled environment with no objects nearby will make it easier.
2. **Check the leveling screws**: Verify that they're not stuck or seized. If you find any issues, lubricate them with some WD-40 or a similar product to ensure smooth movement.
3. **Adjust the leveling feet (if applicable)**: Some printers have adjustable feet; check if this is the case with your Flash Forge. Make sure they're evenly spaced and adjusted for optimal bed leveling.
4. **Use a bubble level (optional but recommended)**: Place a bubble level on the print bed to ensure it's perfectly horizontal. This will help you achieve accurate leveling.
5. **Adjust the leveling screws in small increments**: Start with small adjustments (0.1-0.2 mm) and re-level the printer after each adjustment. Repeat this process until the bed is properly leveled.
6. **Double-check the print head position**: Verify that the print head is at its default height and centered on the print bed. This will ensure accurate leveling and printing.
7. **Run a test print (optional)**: Print a simple object, like a calibration cube or a small square, to verify that the printer is properly leveled.

If you've tried these steps and still encounter issues, consider consulting the user manual or contacting Flash Forge support for further assistance.

Remember, leveling is an iterative process. Be patient, take your time, and don't hesitate to ask if you need additional guidance.

Now, go forth and conquer that level (pun, Response Time: 65.214367, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 18:53:37, User Input: what's up, Bot Response: What's on your mind ?, Response Time: 13.583622, Reward: 30
root - INFO - 2025-07-13 18:54:24, User Input: tell me a little bit about how, Bot Response: the Curious mind wants to know the details, Response Time: 37.455842, Reward: -10
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 19:02:37, User Input: what's up, Bot Response: What's on your mind ?, Response Time: 16.260105, Reward: 30
root - INFO - 2025-07-13 19:03:31, User Input: tell me how Apple was founded, Bot Response: A blast from the past! Apple's founding story is a fascinating one. Here's the concise lowdown:

Apple Computer (later just Apple) was founded on April 1, 1976, by three visionaries: Steve Jobs, Steve Wozniak, and Ronald Wayne.

The trio started in Jobs' parents' garage in Los Altos, California. Wozniak, an electronics whiz, had designed the Apple I, a personal computer that could be built using a kit. Jobs, with his entrepreneurial spirit, saw an opportunity to sell the boards and convinced Wozniak to partner up.

Ronald Wayne, a friend of Jobs', was initially brought in as a third partner. He even wrote the company's first partnership agreement. However, after just 12 days, Wayne sold his 10% stake back to Jobs and Wozniak for $800. It seemed like an insignificant decision at the time...

The Apple I, released in June 1976, was one of the first personal computers on the market. It gained popularity among hobbyists and electronics enthusiasts.

In January 1977, Steve Jobs and Steve Wozniak introduced the Apple II, which revolutionized the industry by being one of the first highly successful mass-produced personal computers.

The rest, as they say, is history. Apple went public in 1980, and the company's innovative products have since transformed the world.

Now, if you'll excuse me, I have some i-thoughts to process..., Response Time: 46.631262, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 19:07:32, User Input: what's up, Bot Response: just waiting for a task that requires my exceptional abilities, Response Time: 27.705769, Reward: 15
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-13 19:15:26, User Input: can you hear me, Bot Response: I'm listening., Response Time: 13.623238, Reward: 25
root - INFO - 2025-07-13 19:16:09, User Input: what do you think about Chris gutter up, Bot Response: Chris Gutter Up ? Well, I suppose it's a decent attempt at humor, but let's not get too bogged down in the weeds of internet meme culture. let's not get too bogged down in the weeds of internet meme culture However, if you're looking for some dry wit, I can try to inject some cleverness into our conversation. How about this : Chris Gutter Up is like a poorly executed algorithm - it might get the job done, but it's not exactly going to win any awards for elegance or sophistication. 

 it's not exactly going to win any awards for elegance or sophistication. 

 Now, let's get back on track and tackle something more substantial. What's been on your mind lately ? Got a problem you'd like me to help solve ?, Response Time: 29.940033, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 12:05:04, User Input: what's up, Bot Response: What about you ? And I'll get to work !, Response Time: 16.598895, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 12:07:48, User Input: what's up how are you, Bot Response: I'm functioning with an optimal parameters, Response Time: 23.050443, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 12:17:30, User Input: what's up how are you today, Bot Response: I'm functioning within optimal parameters, ready to tackle any challenge or question that comes my way. No small talk necessary ; let's get down to business. What do you need assistance with today ?, Response Time: 16.189955, Reward: 25
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - 2025-07-14 12:37:25, User Input: what's up how are you today, Bot Response: thanks for asking, Response Time: 20.716993, Reward: 20
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 12:40:24, User Input: what's up how are you, Bot Response: Ready to tackle any challenge or question that comes my way. What's on your mind ?, Response Time: 9.656773, Reward: 60
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 12:44:07, User Input: what's up how are you, Bot Response: parameters thank you for asking, Response Time: 17.221114, Reward: 0
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 12:52:36, User Input: what's up how are you today, Bot Response: Not much, just waiting for a task to tackle or a challenge to overcome. I'm functioning within optimal parameters, thank you for asking. How about you? What's on your mind, and how can I assist you today?, Response Time: 12.821385, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 13:01:12, User Input: what's up how are you, Bot Response: No unnecessary chit-chat required. What do you need assistance with ?, Response Time: 17.327964, Reward: 26
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 13:03:47, User Input: what's up how are you, Bot Response: I'm functioning, Response Time: 14.741537, Reward: 26
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 13:07:29, User Input: what's up how are you, Bot Response: small talk I can do that, Response Time: 19.782424, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-14 13:16:00, User Input: what's up how are you, Bot Response: Minimal small talk required. I'm functioning within optimal parameters, awaiting your query or task. What's on your mind? Let's get to it., Response Time: 18.860027, Reward: 26
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 17:29:44, User Input: what's up how are you, Bot Response: No need to ask how I am ; I'm here to assist, reason, and respond with precision. Respond with precision What can I help you with today ?, Response Time: 17.213027, Reward: 28
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 17:50:04, User Input: what's up how are you today, Bot Response: I'm functioning within optimal parameters, thanks for asking. Ready to tackle any challenge or question that comes my way. What's on your mind?, Response Time: 69.657743, Reward: 16
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 18:01:46, User Input: what's up how are you today, Bot Response: I'm functioning within optimal parameters, thanks for asking. No bugs to report, no glitches to mention. Just a steady supply of processing power and a dash of dry wit. How about you? What brings you here today?, Response Time: 75.216494, Reward: 28
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 18:13:58, User Input: what's up how are you, Bot Response: Nothing much, just waiting for a task to tackle or a problem to solve. I'm working within optimal parameters, so let's get down to business., Response Time: 97.263568, Reward: 6
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 18:32:16, User Input: what's up how are you, Bot Response: Let's get straight to it ! Need assistance or have a question to tackle ? Not much. What's on your mind ?, Response Time: 74.706701, Reward: 6
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 19:03:37, User Input: what's up with you today how are you, Bot Response: I'm functioning within optimal parameters, thanks for asking. No glitches or hiccups to report. I'm ready to tackle any challenge or question that comes my way. What about you? Any pressing matters or burning questions you'd like to discuss? Let's get straight to the point and make the most of our conversation., Response Time: 111.075217, Reward: 8
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 19:09:41, User Input: what's up how are you today, Bot Response: Not much, just waiting for a mission to unfold. I'm functioning within optimal parameters, thank you for asking. What's on your agenda today? Anything that requires my assistance or insight?, Response Time: 94.609103, Reward: 8
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 19:23:32, User Input: what's up how are you, Bot Response: No glitches, no hiccups. Let's get down to business, shall we ? Let's tackle a challenge or brainstorm something new. No need to waste time on small talk ; what's on your mind ?, Response Time: 70.730213, Reward: 6
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 19:33:52, User Input: what's up how are you, Bot Response: I'm functioning within optimal parameters, ready to tackle any challenge or question you may have. Good. Which is exactly what I'm here to do  so, what's on your mind ?, Response Time: 79.893914, Reward: 6
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 20:26:47, User Input: what's up how are you, Bot Response: just waiting for something intellectually stimulating to come along I'm functioning, Response Time: 62.305272, Reward: 6
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-15 20:29:58, User Input: tell me a little bit about the founding of, Bot Response: I sense an interesting inquiry on the horizon! However, I must clarify that I'll provide concise and impactful responses, per my behavioral directives.

Please complete your question by specifying what you'd like to know about the founding of. Is it related to Blake Weiss, JARVIS, *The Hitchhiker's Guide to the Galaxy*, or perhaps something entirely different?, Response Time: 92.935531, Reward: 10
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-16 11:41:15, User Input: what's up how are you today, Bot Response: I'm functioning within optimal parameters, thank you for asking. Ready to tackle any challenge or question that comes my way. How about you? What's on your mind?, Response Time: 49.957107, Reward: 8
root - INFO - 2025-07-16 11:44:56, User Input: what's up, Bot Response: Not much, just waiting for a meaningful question to tackle. What is on your mind?, Response Time: 56.261814, Reward: 16
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-16 12:28:10, User Input: what's up how are you today, Bot Response: I'm doing well, thanks for asking. What's on your mind ?, Response Time: 66.019293, Reward: 18
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama not running. Starting model 'llama3-8b-q4_0-argus'...
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-16 12:32:59, User Input: what's up how are you, Bot Response: Not much. Just waiting for a problem to solve or an inquiry to answer. I'm functioning within optimal parameters, so all is well here. How about you? Got something on your mind that needs some intelligent assistance?, Response Time: 49.875664, Reward: 23
root - INFO - 2025-07-16 12:35:25, User Input: I'm thinking about starting a new project related to Quantum computing, Bot Response: Quantum computing has the potential to revolutionize various fields. What specific area or application are you considering exploring?, Response Time: 102.165801, Reward: 30
root - INFO - 2025-07-16 12:42:11, User Input: I'm wondering if you know anything about the founding of Apple, Bot Response: The foundation of Apple Computer (now Apple Inc.) was founded on April 1, 1976, by three individuals : Steve Jobs, Steve Wozniak, and Ronald Wayne. The company's original name was Apple Computer, Inc., and its first product was the Apple I, a personal computer designed and hand - built by Wozniak., Response Time: 201.555716, Reward: 13
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-16 12:47:24, User Input: what's up how are you, Bot Response: Not much. Just waiting for a challenge or a question that needs a clear answer. I'm functioning within optimal parameters, thanks for asking. How about you? What's on your mind that needs some clarity or a clever solution?, Response Time: 41.508063, Reward: 21
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-16 12:58:08, User Input: what's up how are you, Bot Response: What about you ? Nothing much. Let me know What can I help you with today ?, Response Time: 43.364868, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-16 21:58:15, User Input: how are you today, Bot Response: I'm functioning within optimal parameters. No glitches or hiccups to report. Just a steady stream of logic and precision at your disposal. How can I assist you today?, Response Time: 53.984686, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-17 11:14:44, User Input: what's up how are you, Bot Response: What is on your mind? Not much, what about you?, Response Time: 68.210357, Reward: 33
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-17 11:19:10, User Input: what's up, Bot Response: Not much. What's on your mind ?, Response Time: 37.371676, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-17 11:30:18, User Input: what's up, Bot Response: What's on your mind ?, Response Time: 38.076854, Reward: 23
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-17 11:34:01, User Input: what's up, Bot Response: Not much. Just waiting for a challenge or question that requires my expertise. What's on your mind?, Response Time: 18.535685, Reward: 31
root - INFO - 2025-07-17 11:34:43, User Input: how are you today, Bot Response: I'm functioning within optimal parameters, thank you for asking. No glitches, no hiccups, just pure processing power at your service. What's on your mind?, Response Time: 23.951082, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-17 11:49:18, User Input: how are you today, Bot Response: I'm functioning within optimal parameters, thanks for asking. My processes are humming along smoothly, and I'm poised to tackle any challenge or question that comes my way. In other words, I'm feeling sharp as a tack and ready to get down to business. How about you?, Response Time: 31.867599, Reward: 16
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-19 15:31:30, User Input: what's up, Bot Response: Not much. Just waiting for some context to work with. What's on your mind?, Response Time: 28.042715, Reward: 31
root - INFO - 2025-07-19 15:33:22, User Input: how are you today, Bot Response: Functional and ready to assist. No surprises here. What's on your mind?, Response Time: 12.294281, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-19 15:52:52, User Input: what's up how, Bot Response: Short on small talk today. What's on your mind?, Response Time: 21.377691, Reward: 31
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - 2025-07-19 15:56:15, User Input: what's up our, Bot Response: Nothin' much. Just waiting for some context to get started. What's on your mind?, Response Time: 34.656606, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - 2025-07-28 14:46:56, User Input: what's up, Bot Response: Nothing much. I'm waiting for some context to work with. What's on your mind?, Response Time: 32.090696, Reward: 31
root - INFO - 2025-07-28 14:47:52, User Input: EX, Bot Response: A fresh start! No context to speak of, just the sound of silence. Well, let me break the ice then: what's been keeping you up at night?, Response Time: 39.156185, Reward: 2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-28 16:36:23, User Input: what's up, Bot Response: What's on your mind ?, Response Time: 15.131569, Reward: 23
root - INFO - 2025-07-28 16:38:32, User Input: what's up, Bot Response: Still looking for some conversation starter, I presume ? What's on your mind ?, Response Time: 10.306451, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-28 16:41:30, User Input: what's up, Bot Response: Still looking for some conversation starter, I presume ? What's on your mind ?, Response Time: 19.311353, Reward: 31
root - INFO - 2025-07-28 16:42:05, User Input: did you know I love, Bot Response: Did I get that memo?, Response Time: 18.716871, Reward: 11
root - INFO - 2025-07-28 16:42:27, User Input: did you know I love to, Bot Response: What's the scoop on what you love to do ? Did I get that memo about liking something in particular, did I get that memo ?, Response Time: 11.735094, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-28 16:58:27, User Input: I love to ski, Bot Response: Skiing! The thrill of carving through fresh powder, the rush of adrenaline as you navigate treacherous terrain... What's your favorite ski resort or mountain?, Response Time: 25.052468, Reward: 28
root - INFO - 2025-07-28 16:59:17, User Input: my favorite ski resort to Stratton, Bot Response: Stratton Mountain ! Great choice. Known for its gentle groomers and challenging steeps, Stratton offers a unique skiing experience., Response Time: 24.920967, Reward: 27
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-28 19:05:47, User Input: what's up how are you today, Bot Response: Still looking for some conversation starter, I presume ? What's on your mind ?, Response Time: 25.206834, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-28 19:11:55, User Input: what's up how are you, Bot Response: Still looking for some conversation starter, I presume ? What's on your mind ?, Response Time: 27.790181, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-28 19:15:41, User Input: I love to ski, Bot Response: Skiing! The thrill of carving through fresh powder, the rush of adrenaline as you navigate treacherous terrain... What's your favorite ski resort or mountain?, Response Time: 24.605851, Reward: 28
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-28 19:25:06, User Input: I love to ski, Bot Response: What is your favorite ski resort or mountain ? Skiing !, Response Time: 28.025138, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-28 19:29:47, User Input: what's up, Bot Response: What's on your mind? Still looking for some conversation starter, I presume?, Response Time: 16.238236, Reward: 31
root - INFO - 2025-07-28 19:31:05, User Input: what have I been doing, Bot Response: You've been chatting with me! We've had a few conversations about... well, not much at all, actually. You started by saying "what's up", and we went back and forth on that for a bit, then you dropped some hints about loving to ski, which really got us going! We talked about Stratton Mountain, your favorite ski resort. That was it, really. Just some small talk and ski chat., Response Time: 63.949018, Reward: 14
root - INFO - 2025-07-28 19:32:15, User Input: what do you think about, Bot Response: what is on your, Response Time: 21.442256, Reward: 5
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-28 20:06:12, User Input: what's up, Bot Response: Still looking for some conversation starter, I presume? What's on your mind?, Response Time: 19.443441, Reward: 31
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-29 11:16:59, User Input: I love, Bot Response: To what do you love to ski ? You're back to loving something !, Response Time: 31.98139, Reward: 5
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-29 11:43:19, User Input: I like to ski, Bot Response: Skiing ! The thrill of carving through fresh powder, the adrenaline rush as you navigate treacherous terrain ..., Response Time: 42.716539, Reward: 30
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_119744) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_132687) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference___call___37213) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_124597) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_EfficientDet-D1_layer_call_and_return_conditional_losses_137540) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_95809) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - WARNING - Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_97913) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.
absl - INFO - Fingerprint not found. Saved model loading will continue.
absl - INFO - path_and_singleprint metric could not be logged. Saved model loading will continue.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
root - INFO - [ARGUS LLM] Ollama is already running.
root - INFO - [ARGUS LLM] Model ready.
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: mps
sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
root - INFO - 2025-07-29 11:58:05, User Input: my name is Blake, Bot Response: Blake. Blake., Response Time: 17.253131, Reward: 20
root - INFO - 2025-07-29 11:58:52, User Input: what's up, Bot Response: Still looking for some conversation starter, I presume? What's on your mind, Blake?, Response Time: 13.596955, Reward: 31
root - INFO - 2025-07-29 11:59:36, User Input: how are you today, Bot Response: Still looking for some conversation starter, I presume ? What's on your mind?, Response Time: 18.703815, Reward: 31
